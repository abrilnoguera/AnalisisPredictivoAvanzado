{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f30f110c",
   "metadata": {},
   "source": [
    "# Una forma avanzada de optimizar hiperparámetros: la optimización bayesiana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760723ef",
   "metadata": {},
   "source": [
    "<img src=\"montaña.jfif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf1b579",
   "metadata": {},
   "source": [
    "- La optimización bayesiana es una técnica para la búsqueda de los mejores hiperparámetros, alternativa al Grid Search y el Random Search.\n",
    "- Permite llegar a óptimos muy cercanos al óptimo global, en una fracción del tiempo que nos llevaría hacerlo con un Grid Search.\n",
    "- Es muy útil sobretodo en modelos como el XGBoost, con muchos hiperparámetros a optimizar.\n",
    "- Típicamente son suficientes entre 50 y 100 iteraciones para alcanzar un desempeño muy cercano al óptimo.\n",
    "\n",
    "Como funciona:\n",
    "- Nos enfrentamos al problema de la optimización global de una función objetivo (**la búsqueda de los mejores hiperparámetros**). \n",
    "- La optimización bayesiana nos provee una técnica basada en el Teorema de Bayes, a fin de resolver este problema de optimización global, que sea a la vez eficaz y eficiente. **La función objetivo será la  métrica que querramos optimizar: AUC, F1, accuracy, etc.**\n",
    "- Funciona construyendo un modelo probabilístico de la función objetivo, llamada función sustituta o *surrogate*. \n",
    "- Esta función surrogate se actualiza, a su vez, con una función de adquisición, que es la responsable de encontrar nuevos puntos para evaluar la función objetivo real.\n",
    "- La función surrogate se basa en la *estadística bayesiana*, en el sentido de actualizar una probabilidad o creencia a priori a la luz de nueva información para generar una creencia o probabilidad a posteriori.\n",
    "\n",
    "\n",
    "*El objetivo final es reducir el número de combinaciones de hiperparámetros con las que se evalúa el modelo, eligiendo únicamente los mejores candidatos.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07c0815",
   "metadata": {},
   "source": [
    "Formamos la función surrogate a partir de los puntos muestrados, siendo x el conjunto de hiperparámetros y c(x) la métrica a optimizar:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df029dc",
   "metadata": {},
   "source": [
    "<img src=\"bo_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea247eb8",
   "metadata": {},
   "source": [
    "Basados en la función surrogate, identificamos qué puntos son mínimos prometedores. Muestreamos más puntos de estas regiones prometedoras y actualizamos la función surrogate...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d64cc",
   "metadata": {},
   "source": [
    "<img src=\"bo_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d2140",
   "metadata": {},
   "source": [
    "La función de adquisición tiene un trade-off de exploración-explotación:\n",
    "- La explotación busca casos adonde el modelo surrogate predice un buen valor de la métrica objetivo. Es decir, que saca provecho de una región conocida y prometedora.\n",
    "- La exploración busca casos en lugares adonde hay mucha incertidumbre. Esto se asegura que no haya grandes regiones del espacio sin explorar.  \n",
    "\n",
    "Una función de adquisición que alienta demasiada explotación con poca exploración llevará a un modelo con un mínimo local allá donde lo encuentre primero, mientras que una función de adquisición que aliente lo puesto nunca hallará un mínimo, ya sea local o global.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ea70c",
   "metadata": {},
   "source": [
    "¿Quieren más teoría?\n",
    "- https://machinelearningmastery.com/what-is-bayesian-optimization/\n",
    "- https://towardsdatascience.com/the-beauty-of-bayesian-optimization-explained-in-simple-terms-81f3ee13b10f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f10ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import auc, RocCurveDisplay \n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0c0626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3656, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Atención: copiar el dataset de la clase 39 a la carpeta Data\n",
    "\n",
    "data_raw = pd.read_csv('./Data/datasets_222487_478477_framingham.csv')\n",
    "data = data_raw.dropna()\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7dd618b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TenYearCHD\n",
       "0    0.731241\n",
       "1    0.131430\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Proporción de clase\n",
    "data.TenYearCHD.value_counts() / data_raw.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d49c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 int64\n",
       "age                  int64\n",
       "education          float64\n",
       "currentSmoker        int64\n",
       "cigsPerDay         float64\n",
       "BPMeds             float64\n",
       "prevalentStroke      int64\n",
       "prevalentHyp         int64\n",
       "diabetes             int64\n",
       "totChol            float64\n",
       "sysBP              float64\n",
       "diaBP              float64\n",
       "BMI                float64\n",
       "heartRate          float64\n",
       "glucose            float64\n",
       "TenYearCHD           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e46bd421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce499765",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop([\"TenYearCHD\"],axis=1)\n",
    "y=data[\"TenYearCHD\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=717)\n",
    "X_test.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e420a225",
   "metadata": {},
   "source": [
    "### Y ahora... un poco de código..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "367887b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2208968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el espacio de búsqueda de hiperparámetros\n",
    "\n",
    "from skopt.space import Integer, Real,Categorical\n",
    "search_space = {'learning_rate': Real(0.01, 1.0, 'uniform'),\n",
    "                 'max_depth': Integer(2, 12),\n",
    "                 'subsample': Real(0.1, 1.0, 'uniform'),\n",
    "                 'colsample_bytree': Real(0.1, 1.0, 'uniform'), # subsample ratio of columns by tree\n",
    "                 'reg_lambda': Real(1e-9, 100., 'uniform'), # L2 regularization\n",
    "                 'reg_alpha': Real(1e-9, 100., 'uniform'), # L1 regularization\n",
    "                 'n_estimators': Integer(50, 1000)\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b375fd4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.72\n",
      "test score: 0.71\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "#Instanciamos el objeto BayesSearchCV\n",
    "opt = BayesSearchCV(\n",
    "    XGBClassifier(),\n",
    "    search_spaces=search_space,\n",
    "    scoring='roc_auc',\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Ajustamos el objeto\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % round(opt.best_score_,2))\n",
    "print(\"test score: %s\" % round(opt.score(X_test, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2891d",
   "metadata": {},
   "source": [
    "- Vemos que mejoramos significativamente el score obtenido con Random Search en CV (0.72 vs 0.70).\n",
    "- También podríamos haber utilizado las mejores combinaciones de HPs obtenidos en Random Search a modo de semilla de la optimización bayesiana"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
